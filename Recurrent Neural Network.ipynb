{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's train a LSTM to write Songs!\n",
    "\n",
    "We're going to use [Keras](https://keras.io)  to write songs. At least 20 epochs are required before the generated text starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57645</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Good Old Days</td>\n",
       "      <td>/z/ziggy+marley/good+old+days_10198588.html</td>\n",
       "      <td>Irie days come on play  \\nLet the angels fly l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57646</th>\n",
       "      <td>Ziggy Marley</td>\n",
       "      <td>Hand To Mouth</td>\n",
       "      <td>/z/ziggy+marley/hand+to+mouth_20531167.html</td>\n",
       "      <td>Power to the workers  \\nMore power  \\nPower to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57647</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Come With Me</td>\n",
       "      <td>/z/zwan/come+with+me_20148981.html</td>\n",
       "      <td>all you need  \\nis something i'll believe  \\nf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57648</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Desire</td>\n",
       "      <td>/z/zwan/desire_20148986.html</td>\n",
       "      <td>northern star  \\nam i frightened  \\nwhere can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57649</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Heartsong</td>\n",
       "      <td>/z/zwan/heartsong_20148991.html</td>\n",
       "      <td>come in  \\nmake yourself at home  \\ni'm a bit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist           song  \\\n",
       "57645  Ziggy Marley  Good Old Days   \n",
       "57646  Ziggy Marley  Hand To Mouth   \n",
       "57647          Zwan   Come With Me   \n",
       "57648          Zwan         Desire   \n",
       "57649          Zwan      Heartsong   \n",
       "\n",
       "                                              link  \\\n",
       "57645  /z/ziggy+marley/good+old+days_10198588.html   \n",
       "57646  /z/ziggy+marley/hand+to+mouth_20531167.html   \n",
       "57647           /z/zwan/come+with+me_20148981.html   \n",
       "57648                 /z/zwan/desire_20148986.html   \n",
       "57649              /z/zwan/heartsong_20148991.html   \n",
       "\n",
       "                                                    text  \n",
       "57645  Irie days come on play  \\nLet the angels fly l...  \n",
       "57646  Power to the workers  \\nMore power  \\nPower to...  \n",
       "57647  all you need  \\nis something i'll believe  \\nf...  \n",
       "57648  northern star  \\nam i frightened  \\nwhere can ...  \n",
       "57649  come in  \\nmake yourself at home  \\ni'm a bit ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Read the entire file containing nietzsche's works\n",
    "path = './data/songdata.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 68056106\n",
      "total chars: 50\n",
      "truncated corpus length: 1000000\n"
     ]
    }
   ],
   "source": [
    "text = df['text'].str.cat(sep='\\n').lower()\n",
    "# Output the length of the corpus\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "\n",
    "# Create a sorted list of the characters\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "# Corpus is going to take tooooo long to train, so lets make it shorter\n",
    "text = text[:1000000]\n",
    "print('truncated corpus length:', len(text))\n",
    "\n",
    "# Create a dictionary where given a character, you can look up the index and vice versa\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates the overlapping windows with target characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 333320\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Step through the text via 3 characters at a time, taking a sequence of 40 bytes at a time. \n",
    "# There will be lots ofo overlap\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen]) # range from current index i for max length characters \n",
    "    next_chars.append(text[i + maxlen]) # the next character after that \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates the 1 hot vectors for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generator(sentences, next_chars, batch_size):\n",
    "    X = np.zeros((batch_size, maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((batch_size, len(chars)), dtype=np.bool)\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    while True:\n",
    "        if index + batch_size >= length:\n",
    "            index = 0\n",
    "        X.fill(0)\n",
    "        y.fill(0)\n",
    "        for i in range(batch_size):\n",
    "            sentence = sentences[index]\n",
    "            for t, char in enumerate(sentence):\n",
    "                X[i, t, char_indices[char]] = 1\n",
    "            y[i, char_indices[next_chars[i]]] = 1\n",
    "            index = index + 1\n",
    "        yield X, y\n",
    "\n",
    "        \n",
    "def getdata(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Compiling model complete...\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "print(\"Compiling model complete...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to sample an index from a probability array\n",
    " The purpose of this function is to add some randomness so that the most likely character is not always chosen, and sometiems the 2nd or 3rd most likely cahracter is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now the actual training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity:  0.25\n",
      "Training...\n",
      "Epoch 1/30\n",
      "333320/333320 [==============================] - 90s - loss: 1.3257    \n",
      "Epoch 2/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.3079    \n",
      "Epoch 3/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.2916    \n",
      "Epoch 4/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.2767    \n",
      "Epoch 5/30\n",
      "333320/333320 [==============================] - 95s - loss: 1.2633    \n",
      "Epoch 6/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.2509    \n",
      "Epoch 7/30\n",
      "333320/333320 [==============================] - 90s - loss: 1.2396    \n",
      "Epoch 8/30\n",
      "333320/333320 [==============================] - 90s - loss: 1.2289    \n",
      "Epoch 9/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.2182    \n",
      "Epoch 10/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.2090    \n",
      "Epoch 11/30\n",
      "333320/333320 [==============================] - 93s - loss: 1.2000    \n",
      "Epoch 12/30\n",
      "333320/333320 [==============================] - 93s - loss: 1.1912    \n",
      "Epoch 13/30\n",
      "333320/333320 [==============================] - 95s - loss: 1.1832    \n",
      "Epoch 14/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1761    \n",
      "Epoch 15/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1694    \n",
      "Epoch 16/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1624    \n",
      "Epoch 17/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1551    \n",
      "Epoch 18/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1502    \n",
      "Epoch 19/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1442    \n",
      "Epoch 20/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1390    \n",
      "Epoch 21/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1348    \n",
      "Epoch 22/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1293    \n",
      "Epoch 23/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1245    \n",
      "Epoch 24/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1205    \n",
      "Epoch 25/30\n",
      "333320/333320 [==============================] - 93s - loss: 1.1172    \n",
      "Epoch 26/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.1126    \n",
      "Epoch 27/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1088    \n",
      "Epoch 28/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.1058    \n",
      "Epoch 29/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1017    \n",
      "Epoch 30/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.0991    \n"
     ]
    }
   ],
   "source": [
    "diversity = 0.25\n",
    "print('Diversity: ', diversity)\n",
    "\n",
    "# Get data\n",
    "X, y = getdata(sentences, next_chars)\n",
    "\n",
    "# The training\n",
    "print('Training...')\n",
    "batch_size = 128\n",
    "#history = model.fit_generator(generator(sentences, next_chars, batch_size),steps_per_epoch=12800, epochs=10)\n",
    "\n",
    "history = model.fit(X, y,batch_size=128, epochs=30)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save('songgenerator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model = load_model('songgenerator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.38376140e-07   1.59899052e-02   2.31494073e-06   3.82331706e-07\n",
      "   8.75291182e-04   2.38516532e-06   9.78216690e-07   1.73993962e-04\n",
      "   1.20980862e-04   2.75911061e-05   1.75383814e-08   1.62562195e-08\n",
      "   2.21796874e-08   2.11789040e-08   6.37657438e-09   7.56524159e-08\n",
      "   2.15332474e-11   3.91719507e-13   1.99961936e-10   1.99581396e-09\n",
      "   1.87422344e-07   3.61256716e-05   4.76284123e-10   7.43869407e-07\n",
      "   1.49717443e-02   1.54660247e-05   7.32398576e-06   6.17988690e-07\n",
      "   2.14238599e-01   3.07571434e-04   1.53765468e-05   2.05547462e-04\n",
      "   8.81461650e-02   1.43233547e-06   1.52318350e-07   5.52391066e-05\n",
      "   1.23053451e-05   1.72923246e-05   6.83942693e-04   6.29356782e-06\n",
      "   3.17800150e-05   8.69943178e-04   1.67908511e-05   2.02791765e-04\n",
      "   2.45523057e-03   3.04941514e-05   2.45122028e-05   3.89928658e-07\n",
      "   6.60446286e-01   5.24280449e-06]\n",
      "0.99999991123\n"
     ]
    }
   ],
   "source": [
    "# Check out what our model predicts\n",
    "sentence = 'behold, my field of cares\\nalas, but there is nothing'\n",
    "sentence = 'familiar like family\\nancient it\\'s gravity'\n",
    "sentence = sentence[:40]\n",
    "x = np.zeros((1, maxlen, len(chars)))\n",
    "for t, char in enumerate(sentence):\n",
    "    x[0, t, char_indices[char]] = 1.\n",
    "    \n",
    "print(model.predict(x, verbose=0)[0])\n",
    "print(sum(model.predict(x, verbose=0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "familiar like family\n",
      "ancient it's gravity  \n",
      "i got a chance to go  \n",
      "  \n",
      "i want you mome to me  \n",
      "  \n",
      "i want to be want to see  \n",
      "you can see in your love  \n",
      "  \n",
      "i want you move to go  \n",
      "  \n",
      "when i feel the story  \n",
      "  \n",
      "we can see the rest of your hours  \n",
      "and i can't get excited  \n",
      "you know i can't feel something  \n",
      "so i couldn't see  \n",
      "you can't tell my friends and i can't tell my thing  \n",
      "i'm going to be my things  \n",
      "i can't get exceted to go  \n",
      "that i\n"
     ]
    }
   ],
   "source": [
    "generated = ''\n",
    "original = sentence\n",
    "# Predict the next 400 characters based on the seed\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, 0.2)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "print(original + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
