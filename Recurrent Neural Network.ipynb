{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Let's train a LSTM to write Songs!\n",
    "\n",
    "We're going to use [Keras](https://keras.io)  to write songs. At least 20 epochs are required before the generated text starts sounding coherent.\n",
    "\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check out the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Read the entire file containing nietzsche's works\n",
    "path = './data/songdata.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['text'].str.cat(sep='\\n').lower()\n",
    "# Output the length of the corpus\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "\n",
    "# Create a sorted list of the characters\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "\n",
    "# Corpus is going to take tooooo long to train, so lets make it shorter\n",
    "text = text[:1000000]\n",
    "print('truncated corpus length:', len(text))\n",
    "\n",
    "# Create a dictionary where given a character, you can look up the index and vice versa\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creates the overlapping windows with target characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "# Step through the text via 3 characters at a time, taking a sequence of 40 bytes at a time. \n",
    "# There will be lots ofo overlap\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen]) # range from current index i for max length characters \n",
    "    next_chars.append(text[i + maxlen]) # the next character after that \n",
    "sentences = np.array(sentences)\n",
    "next_chars = np.array(next_chars)\n",
    "print('Number of sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generates the 1 hot vectors for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generator(sentences, next_chars, batch_size):\n",
    "    X = np.zeros((batch_size, maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((batch_size, len(chars)), dtype=np.bool)\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    while True:\n",
    "        if index + batch_size >= length:\n",
    "            index = 0\n",
    "        X.fill(0)\n",
    "        y.fill(0)\n",
    "        for i in range(batch_size):\n",
    "            sentence = sentences[index]\n",
    "            for t, char in enumerate(sentence):\n",
    "                X[i, t, char_indices[char]] = 1\n",
    "            y[i, char_indices[next_chars[i]]] = 1\n",
    "            index = index + 1\n",
    "        yield X, y\n",
    "\n",
    "        \n",
    "def getdata(sentences, next_chars):\n",
    "    X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "    y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "    length = len(sentences)\n",
    "    index = 0\n",
    "    for i in range(len(sentences)):\n",
    "        sentence = sentences[i]\n",
    "        for t, char in enumerate(sentence):\n",
    "            X[i, t, char_indices[char]] = 1\n",
    "        y[i, char_indices[next_chars[i]]] = 1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "print(\"Compiling model complete...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to sample an index from a probability array\n",
    " The purpose of this function is to add some randomness so that the most likely character is not always chosen, and sometiems the 2nd or 3rd most likely cahracter is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now the actual training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diversity:  0.25\n",
      "Training...\n",
      "Epoch 1/30\n",
      "333320/333320 [==============================] - 90s - loss: 1.3257    \n",
      "Epoch 2/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.3079    \n",
      "Epoch 3/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.2916    \n",
      "Epoch 4/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.2767    \n",
      "Epoch 5/30\n",
      "333320/333320 [==============================] - 95s - loss: 1.2633    \n",
      "Epoch 6/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.2509    \n",
      "Epoch 7/30\n",
      "333320/333320 [==============================] - 90s - loss: 1.2396    \n",
      "Epoch 8/30\n",
      "333320/333320 [==============================] - 90s - loss: 1.2289    \n",
      "Epoch 9/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.2182    \n",
      "Epoch 10/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.2090    \n",
      "Epoch 11/30\n",
      "333320/333320 [==============================] - 93s - loss: 1.2000    \n",
      "Epoch 12/30\n",
      "333320/333320 [==============================] - 93s - loss: 1.1912    \n",
      "Epoch 13/30\n",
      "333320/333320 [==============================] - 95s - loss: 1.1832    \n",
      "Epoch 14/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1761    \n",
      "Epoch 15/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1694    \n",
      "Epoch 16/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1624    \n",
      "Epoch 17/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1551    \n",
      "Epoch 18/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1502    \n",
      "Epoch 19/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1442    \n",
      "Epoch 20/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1390    \n",
      "Epoch 21/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1348    \n",
      "Epoch 22/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1293    \n",
      "Epoch 23/30\n",
      "333320/333320 [==============================] - 89s - loss: 1.1245    \n",
      "Epoch 24/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1205    \n",
      "Epoch 25/30\n",
      "333320/333320 [==============================] - 93s - loss: 1.1172    \n",
      "Epoch 26/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.1126    \n",
      "Epoch 27/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1088    \n",
      "Epoch 28/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.1058    \n",
      "Epoch 29/30\n",
      "333320/333320 [==============================] - 91s - loss: 1.1017    \n",
      "Epoch 30/30\n",
      "333320/333320 [==============================] - 92s - loss: 1.0991    \n"
     ]
    }
   ],
   "source": [
    "diversity = 0.25\n",
    "print('Diversity: ', diversity)\n",
    "\n",
    "# Get data\n",
    "X, y = getdata(sentences, next_chars)\n",
    "\n",
    "# The training\n",
    "print('Training...')\n",
    "batch_size = 128\n",
    "#history = model.fit_generator(generator(sentences, next_chars, batch_size),steps_per_epoch=12800, epochs=10)\n",
    "\n",
    "history = model.fit(X, y,batch_size=128, epochs=30)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "model.save('songgenerator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model = load_model('songgenerator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what our model predicts\n",
    "sentence = 'behold, my field of cares\\nalas, but there is nothing'\n",
    "sentence = 'familiar like family\\nancient it\\'s gravity'\n",
    "sentence = sentence[:40]\n",
    "x = np.zeros((1, maxlen, len(chars)))\n",
    "for t, char in enumerate(sentence):\n",
    "    x[0, t, char_indices[char]] = 1.\n",
    "    \n",
    "print(model.predict(x, verbose=0)[0])\n",
    "print(sum(model.predict(x, verbose=0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = ''\n",
    "original = sentence\n",
    "# Predict the next 400 characters based on the seed\n",
    "for i in range(400):\n",
    "    x = np.zeros((1, maxlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, 0.2)\n",
    "    next_char = indices_char[next_index]\n",
    "\n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "\n",
    "print(original + generated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
